{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import open3d as o3d \n",
    "import mrob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import copy\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import voxel_slam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trajectories_float(input_path, ts_multiplier=1e9):\n",
    "    ts = dict()\n",
    "    with open(input_path) as data:\n",
    "        for line in data:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            line_tokens = line.strip('\\n').split()\n",
    "            \n",
    "            timestamp = float(line_tokens[0]) * ts_multiplier\n",
    "            \n",
    "            trajectory = np.asarray(list(map(float, line_tokens[1:])))\n",
    "            ts.update({timestamp: trajectory})\n",
    "    return ts\n",
    "\n",
    "\n",
    "def trajectory_to_se3(trajectory):\n",
    "    t, Q = trajectory[:3], trajectory[3:]\n",
    "    R = mrob.geometry.SO3(mrob.geometry.quat_to_so3(Q))\n",
    "    return mrob.geometry.SE3(R, t)\n",
    "\n",
    "def read_hilti_sequence(ts_to_quat, ts_to_depth_path, start_of_sequence=0, number_of_clouds=-1, center_distance_threshold=1.5):\n",
    "    poses = []\n",
    "    clouds = []\n",
    "\n",
    "    lidar_so3 = mrob.geometry.SO3(mrob.geometry.quat_to_so3(np.asarray([ 0.7071068, -0.7071068, 0, 0 ])))\n",
    "    lidar_t = np.asarray([ -0.001, -0.00855, 0.055 ])   \n",
    "    imu_to_lidar_se3 = mrob.geometry.SE3(lidar_so3, lidar_t).T()\n",
    "\n",
    "    for ts in sorted(ts_to_quat)[start_of_sequence : start_of_sequence + number_of_clouds]:\n",
    "        imu_pose = trajectory_to_se3(ts_to_quat[ts]).T()\n",
    "\n",
    "        pose = imu_pose @ imu_to_lidar_se3\n",
    "        cloud = o3d.io.read_point_cloud(str(ts_to_depth_path[ts]))\n",
    "        cloud_points = np.asarray(cloud.points)\n",
    "        f = np.where(np.linalg.norm(cloud_points, axis=1) > center_distance_threshold)[0] \n",
    "\n",
    "        cloud.points = o3d.utility.Vector3dVector(cloud_points[f])\n",
    "\n",
    "        cloud.paint_uniform_color([0.0, 0.0, 0.0])\n",
    "        \n",
    "        poses.append(pose)\n",
    "        clouds.append(cloud)\n",
    "\n",
    "    return clouds, poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds_path = \"/home/ach/Desktop/datasets/hilti/out2\"\n",
    "poses_path = \"/home/ach/Desktop/datasets/hilti/exp14_basement_2_imu.txt\"\n",
    "imu_path = \"/home/ach/Desktop/datasets/hilti/hilti_imu.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_multiplier = 1 / 1e9\n",
    "ts_to_depth_path = {float(x.stem) * ts_multiplier : x for x in pathlib.Path(clouds_path).iterdir()}\n",
    "ts_to_quat = parse_trajectories_float(poses_path, ts_multiplier)\n",
    "ts_to_imu = parse_trajectories_float(imu_path, ts_multiplier=ts_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds, poses = read_hilti_sequence(ts_to_quat, ts_to_depth_path, start_of_sequence=320, number_of_clouds=5, center_distance_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_map = voxel_slam.VoxelFeatureMap(clouds, poses, voxel_size=2.0)\n",
    "feature_map = voxel_map.extract_voxel_features(ransac_distance_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_slam.EmptyVoxelsFilter(min_voxel_poses=len(poses)).filter(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inconsistent_voxels(feature_map):\n",
    "    inconsistent_voxels = []\n",
    "\n",
    "    for voxel_id, pose_to_points in feature_map.items():\n",
    "        normals = []\n",
    "        for pose_id, feature_points in pose_to_points.items():\n",
    "            normals.append(feature_points.get_plane_equation()[:-1])\n",
    "        \n",
    "        clustering = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            distance_threshold=0.2,\n",
    "            metric=\"cosine\",\n",
    "            linkage=\"single\",\n",
    "            compute_distances=True,\n",
    "        ).fit(np.asarray(normals))\n",
    "\n",
    "        if clustering.n_clusters_ > 1:\n",
    "            inconsistent_voxels.append(voxel_id)\n",
    "\n",
    "    return inconsistent_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent_voxels = get_inconsistent_voxels(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of voxels: 48\n",
      "Number of inconsistent voxels: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of voxels:\", len(feature_map))\n",
    "print(\"Number of inconsistent voxels:\", len(inconsistent_voxels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(voxel_center, voxel_size):\n",
    "    bounds = []\n",
    "    a = voxel_size / 2\n",
    "    for x in range(2):\n",
    "        for y in range(2):\n",
    "            for z in range(2):\n",
    "                b_box = (voxel_center[0] + a * (-1 if x == 0 else 1),\n",
    "                         voxel_center[1] + a * (-1 if y == 0 else 1),\n",
    "                         voxel_center[2] + a * (-1 if z == 0 else 1))\n",
    "                bounds.append(b_box)\n",
    "\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_centroid(bounding_box: np.ndarray):\n",
    "    return np.apply_along_axis(lambda x: (min(x) + max(x)) / 2, 0, bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_is_in_box(point, bounding_box):\n",
    "    bounding_box = np.asarray(bounding_box)\n",
    "    is_in_box = True \n",
    "    for i in range(3):\n",
    "        is_in_box &= min(bounding_box[:, i]) <= point[i] <= max(bounding_box[:, i]) \n",
    "\n",
    "    return is_in_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_inconsistent(voxel_map: voxel_slam.VoxelFeatureMap, inconsistent_voxels):\n",
    "    voxel_to_pose_points_map = voxel_map._voxel_to_pose_points_map\n",
    "    current_voxel_size = voxel_map.voxel_size\n",
    "    octant_size = current_voxel_size / 2\n",
    "    for voxel_center in inconsistent_voxels:\n",
    "        octant_centers = get_bounding_box(voxel_center, octant_size)\n",
    "        # Add octant-voxels to voxel_map \n",
    "        for oct_center in octant_centers:\n",
    "            if oct_center not in voxel_to_pose_points_map:\n",
    "                voxel_to_pose_points_map[tuple(oct_center)] = {}\n",
    "        \n",
    "        # Assign points to octants\n",
    "        for pose_id, voxel_points in voxel_to_pose_points_map[voxel_center].items():\n",
    "            for point, point_id in zip(voxel_points.points, voxel_points.pcd_idx):\n",
    "                # Find point's octant\n",
    "                for oct_center in octant_centers:\n",
    "                    if point_is_in_box(point, bounding_box=get_bounding_box(oct_center, octant_size)):\n",
    "                        octo_points: voxel_slam.PCDPlane = voxel_to_pose_points_map[oct_center].get(pose_id, voxel_slam.PCDPlane([], []))\n",
    "                        octo_points.add_point(point, point_id)\n",
    "                        voxel_to_pose_points_map[oct_center].update({pose_id: octo_points})\n",
    "\n",
    "        # Pop old voxel center \n",
    "        voxel_to_pose_points_map.pop(voxel_center)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel Map size: 84\n"
     ]
    }
   ],
   "source": [
    "print(\"Voxel Map size:\", len(voxel_map._voxel_to_pose_points_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_inconsistent(voxel_map, inconsistent_voxels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel Map size: 140\n",
      "Inconsistent size 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Voxel Map size:\", len(voxel_map._voxel_to_pose_points_map))\n",
    "print(\"Inconsistent size\", len(inconsistent_voxels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "octo_feature_map = voxel_map.extract_voxel_features(ransac_distance_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length octo feature map 140\n"
     ]
    }
   ],
   "source": [
    "print(\"Length octo feature map\", len(octo_feature_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_slam.EmptyVoxelsFilter(min_voxel_poses=len(poses)).filter(octo_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length octo feature map 43\n"
     ]
    }
   ],
   "source": [
    "print(\"Length octo feature map\", len(octo_feature_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored_clouds, color_to_voxel = voxel_map.get_colored_feature_clouds(octo_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([colored_clouds[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "octo_inconsistent = get_inconsistent_voxels(octo_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(octo_inconsistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_on_minimaps(clouds, poses, minimap_size=5, adaptive_voxelisation_iteration=0):\n",
    "    transformed_clouds = [None for _ in range(len(poses))]\n",
    "    for i in range(len(poses)):\n",
    "        transformed_clouds[i] = copy.deepcopy(clouds[i]).transform(poses[i])\n",
    "\n",
    "    optimized_submaps = []\n",
    "    for i in range(0, len(poses), minimap_size):\n",
    "        voxel_map = voxel_slam.VoxelFeatureMap(\n",
    "            transformed_clouds[i:i+minimap_size],\n",
    "            [np.eye(4) for _ in range(minimap_size)],\n",
    "            voxel_size=2.0\n",
    "        )\n",
    "        feature_map = voxel_map.extract_voxel_features(ransac_distance_threshold=0.02)\n",
    "\n",
    "        for _ in range(adaptive_voxelisation_iteration):\n",
    "            voxel_slam.EmptyVoxelsFilter(min_voxel_poses=minimap_size).filter(feature_map)\n",
    "            inconsistent_voxels = get_inconsistent_voxels(feature_map)\n",
    "            break_inconsistent(voxel_map, inconsistent_voxels)\n",
    "            feature_map = voxel_map.extract_voxel_features(ransac_distance_threshold=0.02)\n",
    "\n",
    "        print(f\"Submap {i}-{i+minimap_size}:\", end=' ')\n",
    "        opt_poses, is_converged, chi2 = voxel_slam.BaregBackend(feature_map, minimap_size).get_optimized_poses(1000, verbose=True)\n",
    "        \n",
    "\n",
    "        optimized_submaps.append(\n",
    "            voxel_slam.aggregate_map(voxel_map.get_colored_feature_clouds(feature_map)[0], opt_poses)\n",
    "        )\n",
    "\n",
    "    aggregate_filter = voxel_slam.EmptyVoxelsFilter(min_voxel_poses=2)\n",
    "\n",
    "    print(\"Aggregated map:\", end=' ')\n",
    "    aggregate_pipeline = voxel_slam.VoxelSLAMPipeline(\n",
    "        feature_filter=aggregate_filter,\n",
    "        optimization_backend=voxel_slam.BaregBackend,\n",
    "        config=voxel_slam.PipelineConfig(voxel_size=2.0, \n",
    "                                         ransac_distance_threshold=0.02, \n",
    "                                         filter_cosine_distance_threshold=0.2,\n",
    "                                         backend_verbose=True)\n",
    "    )\n",
    "\n",
    "    aggregate_output = aggregate_pipeline.process(optimized_submaps, [np.eye(4) for _ in range(len(optimized_submaps))])\n",
    "\n",
    "    o3d.visualization.draw_geometries([\n",
    "        voxel_slam.aggregate_map(aggregate_output.optimized_clouds, aggregate_output.optimized_poses)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds, poses = read_hilti_sequence(ts_to_quat, ts_to_depth_path, start_of_sequence=300, number_of_clouds=60, center_distance_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submap 0-5: FGraph initial error: 5291.338644269284\n",
      "Iteratios to converge: 19\n",
      "Chi2: 5249.787217306715\n",
      "Submap 5-10: FGraph initial error: 4343.404508636594\n",
      "Iteratios to converge: 50\n",
      "Chi2: 4324.000011988296\n",
      "Submap 10-15: FGraph initial error: 37237.4077294608\n",
      "Iteratios to converge: 55\n",
      "Chi2: 34071.197900043444\n",
      "Submap 15-20: FGraph initial error: 28172.02363297886\n",
      "Iteratios to converge: 65\n",
      "Chi2: 18071.091709983295\n",
      "Submap 20-25: FGraph initial error: 22753.193612261017\n",
      "Iteratios to converge: 71\n",
      "Chi2: 15557.856515367312\n",
      "Submap 25-30: FGraph initial error: 118306.9903266087\n",
      "Iteratios to converge: 61\n",
      "Chi2: 111391.31462955617\n",
      "Submap 30-35: FGraph initial error: 503575.11240038206\n",
      "Iteratios to converge: 60\n",
      "Chi2: 478588.00748736283\n",
      "Submap 35-40: FGraph initial error: 494141.67341118737\n",
      "Iteratios to converge: 36\n",
      "Chi2: 491797.23123139696\n",
      "Submap 40-45: FGraph initial error: 860576.0451718922\n",
      "Iteratios to converge: 39\n",
      "Chi2: 825370.3871111659\n",
      "Submap 45-50: FGraph initial error: 46564.08831214292\n",
      "Iteratios to converge: 102\n",
      "Chi2: 37413.911106723805\n",
      "Submap 50-55: FGraph initial error: 54991.30502274168\n",
      "Iteratios to converge: 32\n",
      "Chi2: 48120.75174633042\n",
      "Submap 55-60: FGraph initial error: 30291.967663139687\n",
      "Iteratios to converge: 83\n",
      "Chi2: 24624.009436062275\n",
      "Aggregated map: FGraph initial error: 7488537.346976548\n",
      "Iteratios to converge: 54\n",
      "Chi2: 7488219.421556467\n"
     ]
    }
   ],
   "source": [
    "break_on_minimaps(clouds, poses, minimap_size=5, adaptive_voxelisation_iteration=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submap 0-5: FGraph initial error: 94.13750202794645\n",
      "Iteratios to converge: 7\n",
      "Chi2: 93.41418575470136\n",
      "Submap 5-10: FGraph initial error: 2787.98409933585\n",
      "Iteratios to converge: 0\n",
      "Chi2: 2128.259229705898\n",
      "Submap 10-15: FGraph initial error: 5397.56515618583\n",
      "Iteratios to converge: 43\n",
      "Chi2: 885.6286834233518\n",
      "Submap 15-20: FGraph initial error: 13893.85622700734\n",
      "Iteratios to converge: 36\n",
      "Chi2: 4426.863293249579\n",
      "Submap 20-25: FGraph initial error: 13491.358041704916\n",
      "Iteratios to converge: 77\n",
      "Chi2: 5862.765683015978\n",
      "Submap 25-30: FGraph initial error: 51871.79433437306\n",
      "Iteratios to converge: 59\n",
      "Chi2: 46470.37123700766\n",
      "Submap 30-35: FGraph initial error: 16532.58281818496\n",
      "Iteratios to converge: 75\n",
      "Chi2: 4946.075430239678\n",
      "Submap 35-40: FGraph initial error: 21933.647501313015\n",
      "Iteratios to converge: 45\n",
      "Chi2: 12354.316801628886\n",
      "Submap 40-45: FGraph initial error: 23976.792440574445\n",
      "Iteratios to converge: 66\n",
      "Chi2: 13114.37079069578\n",
      "Submap 45-50: FGraph initial error: 6396.946136695419\n",
      "Iteratios to converge: 80\n",
      "Chi2: 1359.5214646228162\n",
      "Submap 50-55: FGraph initial error: 17030.89795011664\n",
      "Iteratios to converge: 52\n",
      "Chi2: 11025.564680285826\n",
      "Submap 55-60: FGraph initial error: 11647.489532418831\n",
      "Iteratios to converge: 128\n",
      "Chi2: 6881.191396019006\n",
      "Aggregated map: FGraph initial error: 9661492.728713768\n",
      "Iteratios to converge: 50\n",
      "Chi2: 9635698.635844246\n"
     ]
    }
   ],
   "source": [
    "break_on_minimaps(clouds, poses, minimap_size=5, adaptive_voxelisation_iteration=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
