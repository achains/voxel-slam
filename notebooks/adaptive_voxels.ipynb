{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import open3d as o3d \n",
    "import mrob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import copy\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import voxel_slam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_trajectories_float(input_path, ts_multiplier=1e9):\n",
    "    ts = dict()\n",
    "    with open(input_path) as data:\n",
    "        for line in data:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            line_tokens = line.strip('\\n').split()\n",
    "            \n",
    "            timestamp = float(line_tokens[0]) * ts_multiplier\n",
    "            \n",
    "            trajectory = np.asarray(list(map(float, line_tokens[1:])))\n",
    "            ts.update({timestamp: trajectory})\n",
    "    return ts\n",
    "\n",
    "\n",
    "def trajectory_to_se3(trajectory):\n",
    "    t, Q = trajectory[:3], trajectory[3:]\n",
    "    R = mrob.geometry.SO3(mrob.geometry.quat_to_so3(Q))\n",
    "    return mrob.geometry.SE3(R, t)\n",
    "\n",
    "def read_hilti_sequence(ts_to_quat, ts_to_depth_path, start_of_sequence=0, number_of_clouds=-1, center_distance_threshold=1.5):\n",
    "    poses = []\n",
    "    clouds = []\n",
    "\n",
    "    lidar_so3 = mrob.geometry.SO3(mrob.geometry.quat_to_so3(np.asarray([ 0.7071068, -0.7071068, 0, 0 ])))\n",
    "    lidar_t = np.asarray([ -0.001, -0.00855, 0.055 ])   \n",
    "    imu_to_lidar_se3 = mrob.geometry.SE3(lidar_so3, lidar_t).T()\n",
    "\n",
    "    for ts in sorted(ts_to_quat)[start_of_sequence : start_of_sequence + number_of_clouds]:\n",
    "        imu_pose = trajectory_to_se3(ts_to_quat[ts]).T()\n",
    "\n",
    "        pose = imu_pose @ imu_to_lidar_se3\n",
    "        cloud = o3d.io.read_point_cloud(str(ts_to_depth_path[ts]))\n",
    "        cloud_points = np.asarray(cloud.points)\n",
    "        f = np.where(np.linalg.norm(cloud_points, axis=1) > center_distance_threshold)[0] \n",
    "\n",
    "        cloud.points = o3d.utility.Vector3dVector(cloud_points[f])\n",
    "\n",
    "        cloud.paint_uniform_color([0.0, 0.0, 0.0])\n",
    "        \n",
    "        poses.append(pose)\n",
    "        clouds.append(cloud)\n",
    "\n",
    "    return clouds, poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds_path = \"/home/ach/Desktop/datasets/hilti/out2\"\n",
    "poses_path = \"/home/ach/Desktop/datasets/hilti/exp14_basement_2_imu.txt\"\n",
    "imu_path = \"/home/ach/Desktop/datasets/hilti/hilti_imu.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_multiplier = 1 / 1e9\n",
    "ts_to_depth_path = {float(x.stem) * ts_multiplier : x for x in pathlib.Path(clouds_path).iterdir()}\n",
    "ts_to_quat = parse_trajectories_float(poses_path, ts_multiplier)\n",
    "ts_to_imu = parse_trajectories_float(imu_path, ts_multiplier=ts_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds, poses = read_hilti_sequence(ts_to_quat, ts_to_depth_path, start_of_sequence=320, number_of_clouds=5, center_distance_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_map = voxel_slam.VoxelFeatureMap(clouds, poses, voxel_size=2.0)\n",
    "feature_map = voxel_map.extract_voxel_features(ransac_distance_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_slam.EmptyVoxelsFilter(min_voxel_poses=len(poses)).filter(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inconsistent_voxels(feature_map):\n",
    "    inconsistent_voxels = []\n",
    "\n",
    "    for voxel_id, pose_to_points in feature_map.items():\n",
    "        normals = []\n",
    "        for pose_id, feature_points in pose_to_points.items():\n",
    "            normals.append(feature_points.get_plane_equation()[:-1])\n",
    "        \n",
    "        clustering = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            distance_threshold=0.2,\n",
    "            metric=\"cosine\",\n",
    "            linkage=\"single\",\n",
    "            compute_distances=True,\n",
    "        ).fit(np.asarray(normals))\n",
    "\n",
    "        if clustering.n_clusters_ > 1:\n",
    "            inconsistent_voxels.append(voxel_id)\n",
    "\n",
    "    return inconsistent_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent_voxels = get_inconsistent_voxels(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of voxels: 48\n",
      "Number of inconsistent voxels: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of voxels:\", len(feature_map))\n",
    "print(\"Number of inconsistent voxels:\", len(inconsistent_voxels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(voxel_center, voxel_size):\n",
    "    bounds = []\n",
    "    a = voxel_size / 2\n",
    "    for x in range(2):\n",
    "        for y in range(2):\n",
    "            for z in range(2):\n",
    "                b_box = (voxel_center[0] + a * (-1 if x == 0 else 1),\n",
    "                         voxel_center[1] + a * (-1 if y == 0 else 1),\n",
    "                         voxel_center[2] + a * (-1 if z == 0 else 1))\n",
    "                bounds.append(b_box)\n",
    "\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_centroid(bounding_box: np.ndarray):\n",
    "    return np.apply_along_axis(lambda x: (min(x) + max(x)) / 2, 0, bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_is_in_box(point, bounding_box):\n",
    "    bounding_box = np.asarray(bounding_box)\n",
    "    is_in_box = True \n",
    "    for i in range(3):\n",
    "        is_in_box &= min(bounding_box[:, i]) <= point[i] <= max(bounding_box[:, i]) \n",
    "\n",
    "    return is_in_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_inconsistent(voxel_map: voxel_slam.VoxelFeatureMap, \n",
    "                       inconsistent_voxels: list[voxel_slam.VoxelKey], \n",
    "                       voxel_size_threshold):\n",
    "    voxel_to_pose_points_map = voxel_map._voxel_to_pose_points_map\n",
    "    found_inconsistent = False\n",
    "    for voxel_key in inconsistent_voxels:\n",
    "        if voxel_key.size <= voxel_size_threshold:\n",
    "            continue\n",
    "        \n",
    "        found_inconsistent = True \n",
    "        octant_size = voxel_key.size / 2\n",
    "        octant_centers = get_bounding_box(voxel_center=voxel_key.centroid, voxel_size=octant_size)\n",
    "        # Add octant-voxels to voxel_map \n",
    "        for oct_center in octant_centers:\n",
    "            octant_key = voxel_slam.VoxelKey(oct_center, octant_size)\n",
    "            if octant_key not in voxel_to_pose_points_map:\n",
    "                voxel_to_pose_points_map[octant_key] = {}\n",
    "        \n",
    "        # Assign points to octants\n",
    "        for pose_id, voxel_points in voxel_to_pose_points_map[voxel_key].items():\n",
    "            for point, point_id in zip(voxel_points.points, voxel_points.pcd_idx):\n",
    "                # Find point's octant\n",
    "                for oct_center in octant_centers:\n",
    "                    octant_key = voxel_slam.VoxelKey(oct_center, octant_size)\n",
    "                    if point_is_in_box(point, bounding_box=get_bounding_box(oct_center, octant_size)):\n",
    "                        octo_points: voxel_slam.Voxel = voxel_to_pose_points_map[octant_key].get(pose_id, voxel_slam.VoxelPoints([], []))\n",
    "                        octo_points.add_point(point, point_id)\n",
    "                        voxel_to_pose_points_map[octant_key].update({pose_id: octo_points})\n",
    "\n",
    "        # Pop old voxel center \n",
    "        voxel_to_pose_points_map.pop(voxel_key)\n",
    "    return found_inconsistent\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel Map size: 84\n"
     ]
    }
   ],
   "source": [
    "print(\"Voxel Map size:\", len(voxel_map._voxel_to_pose_points_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "break_inconsistent(voxel_map, inconsistent_voxels, voxel_size_threshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel Map size: 140\n",
      "Inconsistent size 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Voxel Map size:\", len(voxel_map._voxel_to_pose_points_map))\n",
    "print(\"Inconsistent size\", len(inconsistent_voxels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "octo_feature_map = voxel_map.extract_voxel_features(ransac_distance_threshold=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length octo feature map 140\n"
     ]
    }
   ],
   "source": [
    "print(\"Length octo feature map\", len(octo_feature_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_slam.EmptyVoxelsFilter(min_voxel_poses=len(poses)).filter(octo_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length octo feature map 43\n"
     ]
    }
   ],
   "source": [
    "print(\"Length octo feature map\", len(octo_feature_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored_clouds, color_to_voxel = voxel_map.get_colored_feature_clouds(octo_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([colored_clouds[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "octo_inconsistent = get_inconsistent_voxels(octo_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(octo_inconsistent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_on_minimaps(clouds, poses, minimap_size=5, adaptive_voxelisation_threshold=0.25):\n",
    "    transformed_clouds = [None for _ in range(len(poses))]\n",
    "    for i in range(len(poses)):\n",
    "        transformed_clouds[i] = copy.deepcopy(clouds[i]).transform(poses[i])\n",
    "\n",
    "    optimized_submaps = []\n",
    "    for i in range(0, len(poses), minimap_size):\n",
    "        voxel_map = voxel_slam.VoxelFeatureMap(\n",
    "            transformed_clouds[i:i+minimap_size],\n",
    "            [np.eye(4) for _ in range(minimap_size)],\n",
    "            voxel_size=2.0\n",
    "        )\n",
    "        feature_map = voxel_map.extract_voxel_features(ransac_distance_threshold=0.01)\n",
    "\n",
    "        has_inconsistent = True\n",
    "        adaptive_iterations = 0\n",
    "        while has_inconsistent:\n",
    "            adaptive_iterations += 1\n",
    "            voxel_slam.EmptyVoxelsFilter(min_voxel_poses=minimap_size).filter(feature_map)\n",
    "            inconsistent_voxels = get_inconsistent_voxels(feature_map)\n",
    "            has_inconsistent = break_inconsistent(voxel_map, inconsistent_voxels, adaptive_voxelisation_threshold)\n",
    "            if has_inconsistent:\n",
    "                feature_map = voxel_map.extract_voxel_features(ransac_distance_threshold=0.02)\n",
    "\n",
    "        print(f\"Submap {i}-{i+minimap_size}:\", end='\\n')\n",
    "        print(\"adaptive_iterations =\", adaptive_iterations, end='\\n')\n",
    "        opt_poses, is_converged, chi2 = voxel_slam.BaregBackend(feature_map, minimap_size).get_optimized_poses(1000, verbose=True)\n",
    "        print(\"====\")\n",
    "\n",
    "        optimized_submaps.append(\n",
    "            voxel_slam.aggregate_map(voxel_map.get_colored_feature_clouds(feature_map)[0], opt_poses)\n",
    "        )\n",
    "\n",
    "    aggregate_filter = voxel_slam.EmptyVoxelsFilter(min_voxel_poses=2)\n",
    "\n",
    "    print(\"Aggregated map:\", end=' ')\n",
    "    aggregate_pipeline = voxel_slam.VoxelSLAMPipeline(\n",
    "        feature_filter=aggregate_filter,\n",
    "        optimization_backend=voxel_slam.BaregBackend,\n",
    "        config=voxel_slam.PipelineConfig(voxel_size=2.0, \n",
    "                                         ransac_distance_threshold=0.02, \n",
    "                                         filter_cosine_distance_threshold=0.2,\n",
    "                                         backend_verbose=True)\n",
    "    )\n",
    "    o3d.visualization.draw_geometries(optimized_submaps)\n",
    "    aggregate_output = aggregate_pipeline.process(optimized_submaps, [np.eye(4) for _ in range(len(optimized_submaps))])\n",
    "    \n",
    "    o3d.visualization.draw_geometries([\n",
    "        voxel_slam.aggregate_map(aggregate_output.optimized_clouds, aggregate_output.optimized_poses)\n",
    "    ])\n",
    "    \n",
    "    # \"\"\"Optimization on new poses\"\"\"\n",
    "    # for voxel_key in feature_map:\n",
    "    #     for pose_id, voxel_points in feature_map[voxel_key].items():\n",
    "    #         pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(voxel_points.points))\n",
    "    #         pcd.transform(opt_poses[pose_id])\n",
    "    #         feature_map[voxel_key][pose_id].points = np.asarray(pcd.points)\n",
    "    \n",
    "    # opt_poses_new, _, _ = voxel_slam.EFBackend(feature_map, len(optimized_submaps)).get_optimized_poses(1000, verbose=True)\n",
    "\n",
    "    # o3d.visualization.draw_geometries([\n",
    "    #     voxel_slam.aggregate_map(aggregate_output.optimized_clouds, opt_poses_new)\n",
    "    # ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds, poses = read_hilti_sequence(ts_to_quat, ts_to_depth_path, start_of_sequence=300, number_of_clouds=12, center_distance_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submap 0-3:\n",
      "adaptive_iterations = 5\n",
      "FGraph initial error: 46.172770395037574\n",
      "Iteratios to converge: 13\n",
      "Chi2: 45.885932064011165\n",
      "====\n",
      "Submap 3-6:\n",
      "adaptive_iterations = 6\n",
      "FGraph initial error: 10.510215428492893\n",
      "Iteratios to converge: 2\n",
      "Chi2: 9.867560070090812\n",
      "====\n",
      "Submap 6-9:\n",
      "adaptive_iterations = 4\n",
      "FGraph initial error: 337.30842286062426\n",
      "Iteratios to converge: 17\n",
      "Chi2: 127.26881832276861\n",
      "====\n",
      "Submap 9-12:\n",
      "adaptive_iterations = 5\n",
      "FGraph initial error: 354.28287769199295\n",
      "Iteratios to converge: 49\n",
      "Chi2: 82.1392224062466\n",
      "====\n",
      "Aggregated map: FGraph initial error: 46566.146485661484\n",
      "Iteratios to converge: 50\n",
      "Chi2: 41768.222137225064\n",
      "FGraph initial error: 37.41868722906041\n",
      "Iteratios to converge: 0\n",
      "Chi2: 26.169404122626112\n"
     ]
    }
   ],
   "source": [
    "break_on_minimaps(clouds, poses, minimap_size=3, adaptive_voxelisation_threshold=0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submap 0-3:\n",
      "adaptive_iterations = 5\n",
      "FGraph initial error: 31.302525458660384\n",
      "Iteratios to converge: 5\n",
      "Chi2: 30.96190709059156\n",
      "====\n",
      "Submap 3-6:\n",
      "adaptive_iterations = 3\n",
      "FGraph initial error: 22.36229416424791\n",
      "Iteratios to converge: 6\n",
      "Chi2: 21.571443504751954\n",
      "====\n",
      "Submap 6-9:\n",
      "adaptive_iterations = 3\n",
      "FGraph initial error: 290.9925047426504\n",
      "Iteratios to converge: 72\n",
      "Chi2: 81.67564881940964\n",
      "====\n",
      "Submap 9-12:\n",
      "adaptive_iterations = 4\n",
      "FGraph initial error: 5073.94134816551\n",
      "Iteratios to converge: 18\n",
      "Chi2: 223.94948248324826\n",
      "====\n",
      "Submap 12-15:\n",
      "adaptive_iterations = 5\n",
      "FGraph initial error: 5921.33742573363\n",
      "Iteratios to converge: 84\n",
      "Chi2: 733.778401947875\n",
      "====\n",
      "Submap 15-18:\n",
      "adaptive_iterations = 4\n",
      "FGraph initial error: 27549.340670163103\n",
      "Iteratios to converge: 76\n",
      "Chi2: 1430.7386783848783\n",
      "====\n",
      "Submap 18-21:\n",
      "adaptive_iterations = 5\n",
      "FGraph initial error: 128684.88649299917\n",
      "Iteratios to converge: 221\n",
      "Chi2: 4846.173162920983\n",
      "====\n",
      "Submap 21-24:\n",
      "adaptive_iterations = 4\n",
      "FGraph initial error: 240570.59458982595\n",
      "Iteratios to converge: 177\n",
      "Chi2: 13241.056017399485\n",
      "====\n",
      "Submap 24-27:\n",
      "adaptive_iterations = 5\n",
      "FGraph initial error: 334417.6135133697\n",
      "Iteratios to converge: 486\n",
      "Chi2: 6860.7833005890425\n",
      "====\n",
      "Submap 27-30:\n",
      "adaptive_iterations = 5\n",
      "FGraph initial error: 80186.47174051551\n",
      "Iteratios to converge: 82\n",
      "Chi2: 14689.613541842342\n",
      "====\n",
      "Aggregated map: FGraph initial error: 18024381.539734613\n",
      "Iteratios to converge: 75\n",
      "Chi2: 11394906.234626943\n"
     ]
    }
   ],
   "source": [
    "break_on_minimaps(clouds, [np.eye(4) for _ in range(len(clouds))], minimap_size=3, adaptive_voxelisation_threshold=0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
